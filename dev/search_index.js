var documenterSearchIndex = {"docs":
[{"location":"rates/#Estimating-fixation-and-polymorphic-rates-considering-generalized-model-of-selection-and-linkage-1","page":"Rates","title":"Estimating fixation and polymorphic rates considering generalized model of selection and linkage","text":"","category":"section"},{"location":"rates/#","page":"Rates","title":"Rates","text":"Before executing the rate estimation, you need to load Distributed module and add some threads","category":"page"},{"location":"rates/#","page":"Rates","title":"Rates","text":"using Distributed\naddprocs(7)","category":"page"},{"location":"rates/#","page":"Rates","title":"Rates","text":"Then you need to declare the Analytical module in all the threads using @everywhere macro. Otherwise, the Analytical module will perform the estimation just using the main core","category":"page"},{"location":"rates/#","page":"Rates","title":"Rates","text":"@everywhere using Analytical, ParallelUtilites\nusing CSV, DataFrames, JLD2, ProgressMeter","category":"page"},{"location":"rates/#","page":"Rates","title":"Rates","text":"Declare a variable containing some basic information about your model. We used a sample size of 661 to perform later analysis over TGP data. The selected Derived Alleles Counts (dac) will be used to compute summary statistics and perform ABC inference","category":"page"},{"location":"rates/#","page":"Rates","title":"Rates","text":"adap              = Analytical.parameters(n=661,dac=[1,2,4,5,10,20,50,100,200,400,500,661,925,1000], al=0.184)\nconvolutedSamples = Analytical.binomialDict()\nAnalytical.binomOp!(adap,convolutedSamples.bn)","category":"page"},{"location":"rates/#","page":"Rates","title":"Rates","text":"The function Analytical.rates will perform the analytical estimation of N independent models regarding DFE, BGS, mutation rate, and recombination rate. In the following example, we declared the prior distribution for each model parameter. We show how to compute summary statistics in the following section","category":"page"},{"location":"rates/#","page":"Rates","title":"Rates","text":"Note that Analytical.rates is the most resource and time-consuming function. In our case, the function will estimate 10^5 independent models. Each model solves the estimation for all possible BGS values. We used BGS values from 0.1 to 0.999 in 5% increments. In total, the example will produce 3.7 million estimates. We have used a hierarchical data structure (HDF5) to facilitate model parameters and rates storage.","category":"page"},{"location":"rates/#","page":"Rates","title":"Rates","text":"The following example took about 1.5 hours to execute on the hardware described at section Infering the rate and strength of adaptation","category":"page"},{"location":"rates/#","page":"Rates","title":"Rates","text":"@time df = Analytical.rates(param = adap,convolutedSamples=convolutedSamples,gH=collect(200:2000),gL=collect(1:10),gamNeg=collect(-2000:-200),iterations = 10^5,shape=adap.al,output=\"${HOME}/rates.jld2\",);","category":"page"},{"location":"rates/#","page":"Rates","title":"Rates","text":"If you have a system with few resources, it is possible to download pre-computed TGP and DGN data rates. Please go to the next section to continue the inference using the pre-computed rates.","category":"page"},{"location":"analytical/#Analytical-estimation-1","page":"Analytical estimations","title":"Analytical estimation","text":"","category":"section"},{"location":"analytical/#Solving-\\alpha_{(x)}-1","page":"Analytical estimations","title":"Solving alpha_(x)","text":"","category":"section"},{"location":"analytical/#","page":"Analytical estimations","title":"Analytical estimations","text":"Our method is based on the analytical solution of alpha_(x) given a genetic scenario. The approach could be extended to any DFE and background selection values to get summary statistics used at ABC methods. This example shows how the asymptotic alpha is affected by linkage and background selection.","category":"page"},{"location":"analytical/#","page":"Analytical estimations","title":"Analytical estimations","text":"Before start, you need to set up a variable of type Analytical.parameters. It is a Mutable structure containing the parameters required to solve the analytical approach. Any value at Analytical.parameters can be easily changed. Remember you need to define before the execution. Otherwise, alpha_(x) will be solved with default values. To change all the values at once, check the variables at the struct Analytical.parameters to set specific models.","category":"page"},{"location":"analytical/#Load-the-modules-1","page":"Analytical estimations","title":"Load the modules","text":"","category":"section"},{"location":"analytical/#","page":"Analytical estimations","title":"Analytical estimations","text":"using Analytical","category":"page"},{"location":"analytical/#Setting-model-parameters-and-convolute-the-binomial-distribution.-1","page":"Analytical estimations","title":"Setting model parameters and convolute the binomial distribution.","text":"","category":"section"},{"location":"analytical/#","page":"Analytical estimations","title":"Analytical estimations","text":"We set a global adaptation rate of 0.4 with a contribution of 0.2 regarding weak adaptation. The process is modeled using a selection coefficient of 500, 10 for strongly and weakly beneficial alleles. We modeled the DFE for deleterious alleles using the values provided at Boyko et al. (2008). ","category":"page"},{"location":"analytical/#","page":"Analytical estimations","title":"Analytical estimations","text":"adap = Analytical.parameters(n=661,alTot=0.4,alLow=0.2,gH=500,gamNeg=-457,al=0.184,be = 0.184/457,B=0.999)","category":"page"},{"location":"analytical/#","page":"Analytical estimations","title":"Analytical estimations","text":"Before solving the model, you must compute the convoluted binomial distribution to down-sampling the SFS","category":"page"},{"location":"analytical/#","page":"Analytical estimations","title":"Analytical estimations","text":"convolutedSamples = Analytical.binomialDict()\nAnalytical.binomOp!(adap,convolutedSamples.bn)","category":"page"},{"location":"analytical/#Solving-the-model-1","page":"Analytical estimations","title":"Solving the model","text":"","category":"section"},{"location":"analytical/#","page":"Analytical estimations","title":"Analytical estimations","text":"Here we solve alpha_(x) generally, using the expected rates. We are not considering any specific mutation process over a locus and branch time. We used the fixation and polymorphic rates since the locus length (L) and the time branch (T) estimations at first order alpha_(x) estimation can be cancelled","category":"page"},{"location":"analytical/#","page":"Analytical estimations","title":"Analytical estimations","text":"mathbbEalpha_(x) approx 1 - fracLT(mathbbEd_S)LT(mathbbEd_N) fracLT(mathbbEp_S(x))LT(mathbbEp_N(x)) approx 1 - fracmathbbEd_SmathbbEd_N fracmathbbEp_S(x)mathbbEp_N(x)","category":"page"},{"location":"analytical/#","page":"Analytical estimations","title":"Analytical estimations","text":"where fracLTLT with a constant mutation rate tend to 1. ","category":"page"},{"location":"analytical/#","page":"Analytical estimations","title":"Analytical estimations","text":"x,y = Analytical.analyticalAlpha(param = adap, convolutedSamples = convolutedSamples)","category":"page"},{"location":"analytical/#","page":"Analytical estimations","title":"Analytical estimations","text":"Internally the function (1) sets the mutation rate regarding the BGS strength and (2) sets the probability of fixations given the genetic scenario. Then, it estimates the SFS and fixations rates for neutral and non-neutral alleles. Please check Analytical.analyticalAlpha to check the process.","category":"page"},{"location":"analytical/#Plotting-the-results.-1","page":"Analytical estimations","title":"Plotting the results.","text":"","category":"section"},{"location":"analytical/#","page":"Analytical estimations","title":"Analytical estimations","text":"The variable x contains alpha_(x) accounting for weakly beneficial alleles. y contains the value of alpha_(x), not accounting for weakly beneficial alleles. In this example, we do not model BGS (check B parameter in Analytical.parameters above)","category":"page"},{"location":"analytical/#","page":"Analytical estimations","title":"Analytical estimations","text":"In Julia, you can easily use R using the module RCall. Please check you have installed R in your system. Nonetheless, you can plot using the Julia Plots module.","category":"page"},{"location":"analytical/#","page":"Analytical estimations","title":"Analytical estimations","text":"If you are using our Docker or Singularity image, you don't need to install anything. Otherwise, install RCall just in case you want to plot using R","category":"page"},{"location":"analytical/#","page":"Analytical estimations","title":"Analytical estimations","text":"using Pkg\nPkg.add(\"RCall\")","category":"page"},{"location":"analytical/#","page":"Analytical estimations","title":"Analytical estimations","text":"using RCall\n\nR\"\"\"\n\tlibrary(ggplot2)\n\tlibrary(reshape2)\n\tdf = data.frame(f=seq(1,length($x)),x=$x,y=$y)\n\td  = melt(df,id.vars='f')\n\tp = ggplot(df,aes(x=f,y=value,color=variable)) + geom_line() + geom_point() + scale_colour_manual(values=c('#30504f', '#e2bd9a'),labels = c(\"Nuetral + deleterious alleles\", \"All alleles\")) + theme_bw()\n\tp\n\"\"\"","category":"page"},{"location":"analytical/#","page":"Analytical estimations","title":"Analytical estimations","text":"(Image: image)","category":"page"},{"location":"data/#Parsing-genomic-data-1","page":"Processing data","title":"Parsing genomic data","text":"","category":"section"},{"location":"data/#","page":"Processing data","title":"Processing data","text":"The module includes functions to parse TGP from Uricchio et al. (2019) and DGN from Murga-Moreno et al. (2019). In addition, the module have a function to parse SFS and divergence from multi-FASTA data following Murga-Moreno et al. (2019)","category":"page"},{"location":"data/#","page":"Processing data","title":"Processing data","text":"Please to parse raw data into SFS and divergence counts, first download raw files deposited in our repository:  ","category":"page"},{"location":"data/#","page":"Processing data","title":"Processing data","text":"TGP  \nDGN Zambia population  \nDGN Raleigh population  ","category":"page"},{"location":"data/#Parsing-TGP-and-DGN-data-1","page":"Processing data","title":"Parsing TGP and DGN data","text":"","category":"section"},{"location":"data/#","page":"Processing data","title":"Processing data","text":"Once you have downloaded the files, you can use the function Analytical.parseSfs to convert the data into SFS and divergence counts. Please check Analytical.parseSfs to get more info.","category":"page"},{"location":"data/#","page":"Processing data","title":"Processing data","text":"alpha, sfs, divergence = Analytical.parseSfs(sampleSize = 661, data = \"/home/jmurga/tgpData/tgp.txt\")","category":"page"},{"location":"data/#","page":"Processing data","title":"Processing data","text":"To save the data, you can use CSV and DataFrames packages","category":"page"},{"location":"data/#","page":"Processing data","title":"Processing data","text":"using CSV, DataFrames\nCSV.write(\"/home/jmurga/tgpData/tgpSfs.tsv\",DataFrame(sfs),delim='\\t',header=false))\nCSV.write(\"/home/jmurga/tgpData/tgpDiv.tsv\",DataFrame(permutedims(divergence)),delim='\\t',header=false))","category":"page"},{"location":"data/#","page":"Processing data","title":"Processing data","text":"It is possible to directly subset genes IDs using Ensembl or Flybase id. Use a variable of type Matrix{String,1} into the argument geneList","category":"page"},{"location":"data/#","page":"Processing data","title":"Processing data","text":"ensemblList = CSV.read(\"/home/jmurga/tgpData/ensemblList.txt\",header=false,DataFrame) |> Array\n\nalpha, sfs, divergence = Analytical.parseSfs(sampleSize = 661, data = \"/home/jmurga/tgpData/tgp.txt\",geneList = ensemblList)","category":"page"},{"location":"data/#","page":"Processing data","title":"Processing data","text":"If you are going to parse DGN, you need to change the value of the argument isoline to true. Following the Murga-Moreno et al. (2019) sample size for each population is:","category":"page"},{"location":"data/#","page":"Processing data","title":"Processing data","text":"Zambia population: 154\nRAL population: 160","category":"page"},{"location":"data/#","page":"Processing data","title":"Processing data","text":"alpha, sfs, divergence = Analytical.parseSfs(sampleSize = 160, data = \"/home/jmurga/dgnRal.txt\",isolines=true)","category":"page"},{"location":"data/#Processing-muti-FASTA-files-1","page":"Processing data","title":"Processing muti-FASTA files","text":"","category":"section"},{"location":"data/#","page":"Processing data","title":"Processing data","text":"We included some tools to process multi-FASTA files into unfolded SFS and divergence. The function Analytical.uSfsFromFasta needs three files: a reference file to degenerate the sequence and a multi-FASTA file to process the polymorphism, and an outgroup sequence to process the divergence. Consider downloading DGN data from John Pool lab or PopFly to obtain these files.","category":"page"},{"location":"data/#","page":"Processing data","title":"Processing data","text":"<!-- sfs, div = Analytical.uSfsFromFasta(\n                        file = \"/home/jmurga/Downloads/example.fa\",\n                        reference  = \"/home/jmurga/Downloads/ref.fa\",\n                        outgroup   = \"/home/jmurga/Downloads/outgroups.fa\",\n                        samples    = 160,\n                        bins       = 20,\n                        codonTable = \"standard\"\n                     ) -->","category":"page"},{"location":"data/#","page":"Processing data","title":"Processing data","text":"The scripts transforms a multi-FASTA file into a matrix which eliminates the monomorphic sites and process the divergent and polymorphic sites. Only 0-fold and 4-fold sites are analyzed as proxy of neutral and selected alleles. The following matrix correspond to the matrix processed at the above example.","category":"page"},{"location":"data/#","page":"Processing data","title":"Processing data","text":"<!-- 162×153456 Array{Char,2}:\n '0'  '0'  '0'  '0'  '0'  '0'  '4'  …  '0'  '0'  '4'  '0'  '0'  '0'\n 'A'  'A'  'G'  'A'  'C'  'C'  'T'     'G'  'G'  'C'  'A'  'G'  'T'\n 'A'  'A'  'G'  'A'  'C'  'C'  'T'     'G'  'G'  'C'  'A'  'G'  'T'\n 'A'  'A'  'G'  'A'  'C'  'C'  'T'     'G'  'G'  'C'  'A'  'G'  'T'\n 'A'  'A'  'G'  'A'  'C'  'C'  'T'     'G'  'G'  'C'  'A'  'G'  'T'\n 'A'  'A'  'G'  'A'  'C'  'C'  'T'  …  'G'  'G'  'C'  'A'  'G'  'T'\n 'A'  'A'  'G'  'A'  'C'  'C'  'T'     'G'  'G'  'C'  'A'  'G'  'T'\n 'A'  'A'  'G'  'A'  'C'  'C'  'T'     'G'  'G'  'C'  'A'  'G'  'T'\n ⋮                        ⋮         ⋱  ⋮                        ⋮\n 'A'  'A'  'G'  'A'  'C'  'C'  'T'     'G'  'G'  'C'  'A'  'G'  'T'\n 'A'  'A'  'G'  'A'  'C'  'C'  'T'  …  'G'  'G'  'C'  'A'  'G'  'T'\n 'A'  'A'  'G'  'A'  'C'  'C'  'T'     'G'  'G'  'C'  'A'  'G'  'T'\n 'A'  'A'  'G'  'A'  'C'  'C'  'T'     'G'  'G'  'C'  'A'  'G'  'T'\n 'A'  'A'  'G'  'A'  'C'  'C'  'T'     'G'  'G'  'C'  'A'  'G'  'T'\n 'A'  'A'  'G'  'A'  'C'  'C'  'T'     'G'  'G'  'C'  'A'  'G'  'T'\n 'A'  'A'  'G'  'A'  'C'  'C'  'T'  …  'G'  'G'  'C'  'A'  'G'  'T'\n 'A'  'A'  'G'  'C'  'C'  'A'  'T'     'G'  'G'  'C'  'A'  'G'  'T' -->","category":"page"},{"location":"data/#","page":"Processing data","title":"Processing data","text":"Each column correspond to a sample position. Only fixed divergence and biallelic sites are process. The matrix is iterated through columns to discard the rest of the cases. The matrix is iterated to check the columns independently. In this way we check fixed divergence or biallelic polymorphism. For example at the following array all polymorphic positions (from row 2 to row 161) correspond to 'A' nucleotides where as the outgroup (last row) correspond to 'G'. This columns is addedas to neutral or selected divergence depedending on the first row value:","category":"page"},{"location":"data/#","page":"Processing data","title":"Processing data","text":"<!-- 162×1 Array{Char,1}:\n '0'\n 'A'\n 'A'\n 'A'\n 'A'\n 'A'\n 'A'\n 'A'\n ⋮  \n 'A'\n 'A'\n 'A'\n 'A'\n 'A'\n 'A'\n 'A'\n 'C' -->","category":"page"},{"location":"data/#","page":"Processing data","title":"Processing data","text":"The next example represent one polymorphic site taking into account the derived allele. At this array, the first 3 polymorphic positions correspond to 'G' where as the rest of polymorphic sites correspond to C. Since 'C' is the ancestral nucleotide (last row) the derived allele frequency will be 3/160:","category":"page"},{"location":"data/#","page":"Processing data","title":"Processing data","text":"<!-- 162×1 Array{Char,1}:\n '4'\n 'G'\n 'G'\n 'G'\n 'C'\n 'C'\n 'C'\n 'C'\n ⋮  \n 'C'\n 'C'\n 'C'\n 'C'\n 'C'\n 'C'\n 'C'\n 'C' -->","category":"page"},{"location":"input/#Input-data-1","page":"Input data","title":"Input data","text":"","category":"section"},{"location":"input/#","page":"Input data","title":"Input data","text":"To estimate summary statistics, you need to provide empirical SFS and divergence files. As explained in section data, you can directly parse TGP or DGN data using our module. Nonetheless, you can input any other SFS and divergence file.","category":"page"},{"location":"input/#","page":"Input data","title":"Input data","text":"You can easily use Julia to download the files using Julia or Bash. You also can download the files manually","category":"page"},{"location":"input/#","page":"Input data","title":"Input data","text":"download(\"https://raw.githubusercontent.com/jmurga/Analytical.jl/master/data/tgp.txt\",\"/home/jmurga/tgpData/tgp.txt\")","category":"page"},{"location":"input/#","page":"Input data","title":"Input data","text":"The function Analytical.parseSfs will parse the raw data, creating two variables of type: MatrixFloat64andVectorInt64` required to estimate summary statistics.","category":"page"},{"location":"input/#","page":"Input data","title":"Input data","text":"alpha, sfs, divergence = Analytical.parseSfs(sampleSize = 661, data = \"/home/jmurga/tgpData/tgp.txt\")","category":"page"},{"location":"input/#","page":"Input data","title":"Input data","text":"To standardize the estimation next steps, search and read the SFS and divergence file automatically. To do that, you need to create an analysis folder. Please write your SFS and divergence data in the analysis folder using the prefix sfs and div","category":"page"},{"location":"input/#","page":"Input data","title":"Input data","text":"CSV.write(\"/home/jmurga/tgpData/sfsTgp.tsv\",DataFrame(sfs),delim='\\t',header=false)\nCSV.write(\"/home/jmurga/tgpData/divTgp.tsv\",DataFrame(permutedims(divergence)),delim='\\t',header=false)","category":"page"},{"location":"input/#","page":"Input data","title":"Input data","text":"Once you have estimated (or download) the analytical rates and parsed the SFS and divergence information, you can estimate the summary statistics.","category":"page"},{"location":"empirical/#Infering-the-rate-and-strength-of-adaptation-1","page":"Empirical estimation","title":"Infering the rate and strength of adaptation","text":"","category":"section"},{"location":"empirical/#","page":"Empirical estimation","title":"Empirical estimation","text":"We develop an extension of the analytical approximation presented in Uricchio, Petrov, and Enard (2019). In the previous paper, analytical calculations were used to explore the effect of BGS on weakly beneficial alleles, but the estimation procedure employed was based on computationally intensive simulations. While inference procedures based on forward simulations allow for the inclusion of complex demographic histories, they often require high-performance computing resources and can be prohibitively slow for some models. Here we extend Uricchio, Petrov and Enard (2019) analytical approximations to develop a simple and computationally efficient ABC-based inference procedure. Our method accounts for the DFE of deleterious and beneficial alleles and incomplete recombination between selected genomic elements. ","category":"page"},{"location":"empirical/#","page":"Empirical estimation","title":"Empirical estimation","text":"To perform the empirical estimation of alpha_(x) we followed a generic ABC algorithm (Beaumont et al 2002). ABC proceeds by first sampling parameter values from prior distributions, the next simulating model using these parameter values, calculating informative summary statistics, and comparing the simulated summary statistics to the observed data. Considering the standard ABC scheme, we (1) considered N random combinations from prior distributions; (2) solved N independent models to generate informative summary statistics; (3) subset the parameter values producing summary statistics that best match the observed data from an approximate posterior distribution. Additionally, a linear model can be imposed to correct the non-0 distance between the simulated and observed summary statistics.","category":"page"},{"location":"empirical/#Extending-analytical-estimations-1","page":"Empirical estimation","title":"Extending analytical estimations","text":"","category":"section"},{"location":"empirical/#","page":"Empirical estimation","title":"Empirical estimation","text":"We extended the analytical calculations solving N independents models. We automatize the analytical estimations to input prior distributions:","category":"page"},{"location":"empirical/#","page":"Empirical estimation","title":"Empirical estimation","text":"Population-scaled selected coefficient of deleterious alleles \nPopulation-scaled selected coefficient of weakly beneficial alleles \nPopulation-scaled selection coefficient of strong beneficial alleles \nProportion of weakly adaptive substitutions \nProportion of adaptive substitutions \nPopulation-scaled mutation rate at coding locus\nPopulation-scaled recombination rate \nScale parameter \nShape parameter \nBGS strength","category":"page"},{"location":"empirical/#","page":"Empirical estimation","title":"Empirical estimation","text":"The models will be solved using random combinations from prior distributions. Fixation, polymorphic rates, and model information will be used to estimate informative summary statistics needed to perform ABC inference. Please see section rates to check how to input prior distributions.","category":"page"},{"location":"empirical/#Summary-statistics-1","page":"Empirical estimation","title":"Summary statistics","text":"","category":"section"},{"location":"empirical/#","page":"Empirical estimation","title":"Empirical estimation","text":"\\cite{uricchioexploiting2019} used the analytical theory to demonstrate the effect of weakly beneficial alleles at alpha_(x). To do that, they solved alpha_(x) through the fixation and polymorphism rates since the locus length (L) and the time branch (T) estimations at first order alpha_(x) estimation can be canceled","category":"page"},{"location":"empirical/#","page":"Empirical estimation","title":"Empirical estimation","text":"mathbbEalpha_(x) approx 1 - fracLT(mathbbEd_S)LT(mathbbEd_N) fracLT(mathbbEp_S(x))LT(mathbbEp_N(x)) approx 1 - fracmathbbEd_SmathbbEd_N fracmathbbEp_S(x)mathbbEp_N(x)","category":"page"},{"location":"empirical/#","page":"Empirical estimation","title":"Empirical estimation","text":"where fracLTLT with a constant mutation rate tend to 1. ","category":"page"},{"location":"empirical/#","page":"Empirical estimation","title":"Empirical estimation","text":"Here, we extended their analytical calculations to generate the summary statistics required at ABC approaches. Thereby we avoided expensive forward simulations. ","category":"page"},{"location":"empirical/#","page":"Empirical estimation","title":"Empirical estimation","text":"Considering fixed values of T, L, mu, and fixation rates it is possible to solve analytical alpha_(x) performing the multiplication. However, this requires not only branch length estimations but also explicitly locus length selection which highly increases the order of estimations to solve. To avoid branch length estimations and locus length selection, we follow the previously described assumptions: (1) empirically observed fixations should be proportional to T, L and mu; (2) the mutational process follows a Poisson distribution . Based on that premises, we used a Poisson-sampling process to estimate the expected number of fixations. We corrected the analytical expected rates by the empirical observations as the rate of success lambda on the Poisson distribution","category":"page"},{"location":"empirical/#","page":"Empirical estimation","title":"Empirical estimation","text":"mathbbED = X in Poissonleft(lambda = D_observed times (mathbbEd_++mathbbEd_-+mathbbEd_0)right)","category":"page"},{"location":"empirical/#","page":"Empirical estimation","title":"Empirical estimation","text":"To estimate alpha_(x) we draw the expected values considering each fixation category. We sampled the values in two categories according to the relative rates. Following the same procedure:","category":"page"},{"location":"empirical/#","page":"Empirical estimation","title":"Empirical estimation","text":"mathbbED_S = X in Poissonleft(lambda = D_observed times leftfracmathbbEd_0mathbbEd_+ + mathbbEd_- + mathbbEd_0rightright)","category":"page"},{"location":"empirical/#","page":"Empirical estimation","title":"Empirical estimation","text":"mathbbED_N = X in Poissonleft(lambda = D_observed times leftfracmathbbEd_+ + mathbbEd_-mathbbEd_+ + mathbbEd_- + mathbbEd_0rightright)","category":"page"},{"location":"empirical/#","page":"Empirical estimation","title":"Empirical estimation","text":"Our model takes into account that both sampling variance and process variance should affect the number of variable alleles that we sample at any particular allele frequency. The process variance arises from the random mutation-fixation process along the branch. To incorporate that variance we made one sample per frequency-bin given the SFS. Considering the random process at each frequency we made credible intervals for future ABC estimations. Otherwise, we would falsely find higher confidence in our parameter estimates. We draw the expected polymorphic values similarly to fixations, considering the SFS and the expected rates.","category":"page"},{"location":"empirical/#","page":"Empirical estimation","title":"Empirical estimation","text":"mathbbEP = sum_x=0^x=1 X in Poissonleft(lambda = SFS_(x) observed times (mathbbEp_+(x)+mathbbEp_-(x)+mathbbEp_0(x))right)","category":"page"},{"location":"empirical/#","page":"Empirical estimation","title":"Empirical estimation","text":"We modified the expected polymorphic rates and the observed SFS considering each frequency x as the cumulative sum above x. This quantities have the same asymptote but are less affected by changing sample size. Therefore, we scaled better the analysis to sample size since most common alleles at frequencies x have very few polymorphic sites in large samples. This way, we finally transformed alpha_(x) to be depending on the previous frequency bin value, which reflects each frequency category over the expected asymptotic shape. Because of that, alpha_(x) analysis is more robust even in low polymorphic populations.","category":"page"},{"location":"empirical/#","page":"Empirical estimation","title":"Empirical estimation","text":"Consequently, for each analytical combination, it is possible to sample the expected number of fixations and polymorphism to perform the alpha_(x) estimations. Like in \\cite{uricchioexploiting2019} we input alpha_(x) as summary statistic at generic ABC algorithm. We exploited summary statistics selection that are informative for estimating alpha_(x) values.","category":"page"},{"location":"empirical/#Parameters-inference-1","page":"Empirical estimation","title":"Parameters inference","text":"","category":"section"},{"location":"empirical/#","page":"Empirical estimation","title":"Empirical estimation","text":"We used the expected proportion of weakly and strong fixations to estimate alpha_W, alpha_S and alpha. We followed the same procedure as the above section to subset the expected number of fixation taking into account weakly, strong and deleterious fixation rates categories. Therefore, we modified \\hyperref[eqn 19]{eqn 19} according to their relative fixation rates.","category":"page"},{"location":"empirical/#","page":"Empirical estimation","title":"Empirical estimation","text":"mathbbED_W = X in Poissonleft(lambda = D_observed times leftfracmathbbEd_WmathbbEd_+ + mathbbEd_- + mathbbEd_0rightright)","category":"page"},{"location":"empirical/#","page":"Empirical estimation","title":"Empirical estimation","text":"mathbbED_S = X in Poissonleft(lambda = D_observed times leftfracmathbbEd_SmathbbEd_+ + mathbbEd_- + mathbbEd_0rightright)","category":"page"},{"location":"empirical/#","page":"Empirical estimation","title":"Empirical estimation","text":"In addition, for each model, we retrieve negative selection coefficients and shape parameter to perform ABC inference.","category":"page"},{"location":"empirical/#Computational-pipeline-1","page":"Empirical estimation","title":"Computational pipeline","text":"","category":"section"},{"location":"empirical/#","page":"Empirical estimation","title":"Empirical estimation","text":"The following sections describe the whole pipeline to automatize analytical estimations, empirical data parse, summary statistic estimation, and ABC inference.","category":"page"},{"location":"empirical/#","page":"Empirical estimation","title":"Empirical estimation","text":"The software is prepared to parallelize each pipeline step using Julia Distributed computing. Distributing the process into threads has a cost in RAM. Please make some tests in your machine before executing expensive models. Nonetheless, distributing the estimation into threads decreases the pipeline execution time. It is almost mandatory to parallelize at least the rate estimations.","category":"page"},{"location":"empirical/#","page":"Empirical estimation","title":"Empirical estimation","text":"The following examples, as well as the analysis described at REF, were tested using a laptop with the following hardware:","category":"page"},{"location":"empirical/#","page":"Empirical estimation","title":"Empirical estimation","text":"Intel i7-7700HQ (8) @ 3.800GHz \n16GB RAM DDR4 2400MHz","category":"page"},{"location":"abc/#ABC-inference-from-empirical-data-1","page":"ABC inference","title":"ABC inference from empirical data","text":"","category":"section"},{"location":"abc/#","page":"ABC inference","title":"ABC inference","text":"At this point, you have a folder containing summary statistics and observed data to perform ABC inference. As explained in our home page, we performed the ABC inference using ABCreg. However, you can used other ABC software to perform the inference.","category":"page"},{"location":"abc/#","page":"ABC inference","title":"ABC inference","text":"We link ABCreg with Julia to perform ABC inference. If you are going to use ABCreg to make inferences from our software directly, please cite the publication. Remember you need to install ABCreg before continue. Please check home page to install ABCreg.","category":"page"},{"location":"abc/#","page":"ABC inference","title":"ABC inference","text":"It is possible to perform the inference through Julia. The number of parameters to infer will always be 5: alpha_w, alpha_s, alpha, gamma and beta","category":"page"},{"location":"abc/#","page":"ABC inference","title":"ABC inference","text":"Analytical.ABCreg(analysisFolder=\"/home/jmurga/tgpData/\",replicas=100,P=5,S=size(adap.dac,1),tol=0.002,workers=1,abcreg=\"/home/jmurga/ABCreg/src/reg\",parallel=false);","category":"page"},{"location":"abc/#","page":"ABC inference","title":"ABC inference","text":"If you have installed GNU-parallel in your system it is possible to parallelize the inference","category":"page"},{"location":"abc/#","page":"ABC inference","title":"ABC inference","text":"Analytical.ABCreg(analysisFolder=\"/home/jmurga/tgpData/\",replicas=100,P=5,S=size(adap.dac,1),tol=0.002,workers=7,abcreg=\"/home/jmurga/ABCreg/src/reg\",parallel=true);","category":"page"},{"location":"abc/#","page":"ABC inference","title":"ABC inference","text":"We used R to estimate the Maximum-A-Posteriori (MAP) from posterior distributions following ABCreg examples. We linked Julia and R internally. The module contains functions to perform the estimations without quit the Julia session.","category":"page"},{"location":"abc/#","page":"ABC inference","title":"ABC inference","text":"If you will perform MAP estimates and plot using our module, be sure you have installed R and the following packages: ggplot2 and data.table, locfit. ","category":"page"},{"location":"abc/#","page":"ABC inference","title":"ABC inference","text":"Analytical.sourcePlotMapR(script=\"/home/jmurga/tgpData/script.jl\")\ntgpmap = Analytical.plotMap(analysisFolder=\"/home/jmurga/tgpData/\");\ndescribe(tgpmap)","category":"page"},{"location":"abc/#","page":"ABC inference","title":"ABC inference","text":" Row │ variable  mean          min           median        max          nmissing  eltype   \n     │ Symbol    Float64       Float64       Float64       Float64      Int64     DataType \n─────┼─────────────────────────────────────────────────────────────────────────────────────\n   1 │ aw           0.108927     0.010857       0.108796      0.19754          0  Float64\n   2 │ as           0.0506607   -0.00750128     0.0514826     0.134143         0  Float64\n   3 │ a            0.152842     0.0962341      0.149083      0.233131         0  Float64\n   4 │ gamNeg    1184.81       512.458       1277.47       1903.12             0  Float64\n   5 │ shape        0.142934     0.128369       0.14189       0.167394         0  Float64","category":"page"},{"location":"abc/#","page":"ABC inference","title":"ABC inference","text":"<img src=\"https://raw.githubusercontent.com/jmurga/Analytical.jl/master/docs/src/figure2.svg\" alt=\"drawing\" style=\"width:700px;\"/>","category":"page"},{"location":"cli/#Command-Line-Interface-1","page":"Command-Line interface","title":"Command-Line Interface","text":"","category":"section"},{"location":"cli/#","page":"Command-Line interface","title":"Command-Line interface","text":"We develop a Command-Line Interface (CLI) in case you want to avoid Julia interpreter. You can easly download abcmk_cli.jl. The CLI have different functions to perform the whole pipeline as explained in Infering the rate and strength of adaptation section","category":"page"},{"location":"cli/#","page":"Command-Line interface","title":"Command-Line interface","text":"julia abcmk_cli.jl  ","category":"page"},{"location":"cli/#","page":"Command-Line interface","title":"Command-Line interface","text":"See --help of each command for usages  \n  rates  \n  parseTgpData  \n  parseDgnData  \n  summaries  \n  abcInference  \n  plotMap  ","category":"page"},{"location":"cli/#","page":"Command-Line interface","title":"Command-Line interface","text":"To reproduce the examples you can easly:","category":"page"},{"location":"cli/#","page":"Command-Line interface","title":"Command-Line interface","text":"Estimate rates","category":"page"},{"location":"cli/#","page":"Command-Line interface","title":"Command-Line interface","text":"time julia abcmk_cli.jl rates --samples 661 --gamNeg \"-2000 -200\" --gL \"1 10\" --gH \"200 2000\" --rho 0.001 --theta 0.001 --solutions 100000 --output /home/jmurga/rates.jld2 --dac 1,2,4,5,10,20,50,100,200,400,500,661,925,1000 --nthreads 7","category":"page"},{"location":"cli/#","page":"Command-Line interface","title":"Command-Line interface","text":"Parse data into new folder","category":"page"},{"location":"cli/#","page":"Command-Line interface","title":"Command-Line interface","text":"julia abcmk_cli.jl parseData --analysisFolder /home/jmurga/tgpData","category":"page"},{"location":"cli/#","page":"Command-Line interface","title":"Command-Line interface","text":"Estimate summary statistics","category":"page"},{"location":"cli/#","page":"Command-Line interface","title":"Command-Line interface","text":"julia abcmk_cli.jl summaries --analysisFolder /home/jmurga/tgpData/ --rates /home/jmurga/rates.jld2 --samples 661 --replicas 100 --summstatSize 100000 --dac 2,4,5,10,20,50,200,661,925 --nthreads 7","category":"page"},{"location":"cli/#","page":"Command-Line interface","title":"Command-Line interface","text":"Perform ABC inference","category":"page"},{"location":"cli/#","page":"Command-Line interface","title":"Command-Line interface","text":"julia abcmk_cli.jl abcInference --analysisFolder /home/jmurga/tgpData/ --replicas 100 --P 5 --S 9 --tol 0.001 --ABCreg /home/jmurga/ABCreg/src/reg --parallel true --nthreads 7","category":"page"},{"location":"cli/#","page":"Command-Line interface","title":"Command-Line interface","text":"Estimate Maximum-A-Posteriori and plot using R. Using julia expression, cannot input into abcmk_cli.jl (in development)","category":"page"},{"location":"cli/#","page":"Command-Line interface","title":"Command-Line interface","text":"julia -e 'using Analytical, RCall, GZip, DataFrames, CSV;Analytical.sourcePlotMapR(script=\"/home/jmurga/tgpData/script.jl\"); Analytical.plotMap(analysisFolder=\"/home/jmurga/tgpData\");'","category":"page"},{"location":"mk/#MK-approaches-1","page":"MK approaches","title":"MK approaches","text":"","category":"section"},{"location":"mk/#","page":"MK approaches","title":"MK approaches","text":"We included other heuristic MK approaches in our module. All the functions use the formated SFS and divergence data described at data section.","category":"page"},{"location":"mk/#Standard-MKT-1","page":"MK approaches","title":"Standard MKT","text":"","category":"section"},{"location":"mk/#","page":"MK approaches","title":"MK approaches","text":"The standard McDonald & Kreitman test (MKT) (McDonald and Kreitman, 1991) was developed to be applied to protein coding sequences, combining both divergence (D) and polymorphism (P) sites, and categorizing mutations as synonymous (P0, D0) and non-synonymous (Pi, Di). ","category":"page"},{"location":"mk/#","page":"MK approaches","title":"MK approaches","text":"If all mutations are either strongly deleterious or neutral, then DiD0 is expected to roughly equal PiP0. In contrast, if positive selection is operating in the region, adaptive mutations rapidly reach fixation and contribute more to divergence than polymorphism compared to neutral mutations, and then DiD0  PiP0. Assuming that adaptive mutations contribute little to polymorphism but substantially to divergence, the proportion of non-synonymous substitutions is inferred following Smith and Eyre-Walker (2002)","category":"page"},{"location":"mk/#","page":"MK approaches","title":"MK approaches","text":"alpha = 1 - (fracP_iP_0cdotfracD_0D_i)","category":"page"},{"location":"mk/#Fay,-Waycoff-and-Wu-MKT-1","page":"MK approaches","title":"Fay, Waycoff and Wu MKT","text":"","category":"section"},{"location":"mk/#","page":"MK approaches","title":"MK approaches","text":"Fay et al. (2001) proposed an approach that removes all polymorphisms segregating at a frequency below a given threshold (usually 5%–15%). Although there is no consensus about what this threshold should be used, J. Charlesworth & Eyre-Walker (2008) demonstrated that  estimates are robust using a frequency threshold of 15%, below which most slightly deleterious polymorphisms are found and removed. The estimates are reasonably accurate only when the rate of adaptive evolution is high and the Distribution of Fitness Effects (DFE) of deleterious mutations is leptokurtic (J. Charlesworth & Eyre-Walker, 2008).","category":"page"},{"location":"mk/#imputed-MKT-(in-preparation)-1","page":"MK approaches","title":"imputed MKT (in preparation)","text":"","category":"section"},{"location":"mk/#Asymptotic-MKT-1","page":"MK approaches","title":"Asymptotic MKT","text":"","category":"section"},{"location":"mk/#","page":"MK approaches","title":"MK approaches","text":"Proposed by Messer and Petrov (2013). This extension is robust to the presence of selective sweeps (genetic hitchhiking) and the segregation of slightly deleterious polymorphisms substitutions (BGS). In this approach, the authors defined alpha as a function that depends on the SFS of alleles. Therefore, alpha is estimated in different frequency intervals (x), and these values are then adjusted to an exponential function. An exponential fit is suitable as the non-synonymous allele frequency is expected to decay exponentially over the respective levels of synonymous polymorphisms (Messer & Petrov, 2013).","category":"page"},{"location":"mk/#","page":"MK approaches","title":"MK approaches","text":"alpha_fit(x) = a+b cdot e^-cx","category":"page"},{"location":"reference/#Model-parameters-1","page":"Reference","title":"Model parameters","text":"","category":"section"},{"location":"reference/#","page":"Reference","title":"Reference","text":"adap is the only variable exported from Analytical module. It is a Mutable structure contaning the variables required to solve the analytical approach. Any value can be easly changed. Remember adap should be change before the execution, in other case, alpha_(x) will be solve with the default values. To change all the values at once, you can use Analytical.parameters in order to set specific models in a new variable.","category":"page"},{"location":"reference/#","page":"Reference","title":"Reference","text":"Analytical.parameters\nAnalytical.binomialDict\nAnalytical.Br\nAnalytical.setThetaF!\nAnalytical.setPpos!\nAnalytical.binomOp!\nAnalytical.phiReduction\nAnalytical.analyticalAlpha","category":"page"},{"location":"reference/#Analytical.parameters","page":"Reference","title":"Analytical.parameters","text":"Mutable structure containing the variables required to solve the analytical approach. All the functions are solve using the internal values of the structure. For this reason, adap is the only exported variable. Adap should be change before the perform the analytical approach, in other case, $\\alpha_{(x)}$ will be solve with the default values.\n\nParameters\n\ngamNeg::Int64: Selection coefficient for deleterious alleles\ngL::Int64: Selection coefficient for weakly benefical alleles\ngH::Int64: Selection coefficient for strongly benefical alleles\nalLow::Float64: Proportion of α due to weak selection\nalTot::Float64: α\nthetaF::Float64: Mutation rate defining BGS strength\nthetaMidNeutral::Float64: Mutation rate on coding region\nal::Float64: DFE shape parameter \nbe::Float64: DFE scale parameter\nB::Float64: BGS strength\nbRange::Array{Float64,1}: BGS values to simulate\npposL::Float64: Fixation probabily of weakly beneficial alleles\npposH::Float64: Fixation probabily of strongly beneficial alleles\nN::Int64: Population size\nn::Int64: Sample size\nLf::Int64: Flanking region length\nrho::Float64: Recombination rate\nTE::Float64\n\n\n\n\n\n","category":"type"},{"location":"reference/#Analytical.binomialDict","page":"Reference","title":"Analytical.binomialDict","text":"Mutable structure containing the downsampled SFS. \n\nReturns\n\nbn::Dict: SparseMatrixCSC containing the binomial convolution\n\n\n\n\n\n","category":"type"},{"location":"reference/#Analytical.Br","page":"Reference","title":"Analytical.Br","text":"Br(Lmax,theta)\n\nExpected reduction in nucleotide diversity. Explored at Charlesworth B., 1994:\n\nfracpipi_0 = e^frac4muL2rL+t\n\nArguments\n\nparam::parameters\ntheta::Float64\n\nReturns\n\nFloat64: expected reduction in diversity given a non-coding length, mutation rate and defined recombination.\n\n\n\n\n\n","category":"function"},{"location":"reference/#Analytical.setThetaF!","page":"Reference","title":"Analytical.setThetaF!","text":"setThetaF!(param)\n\nFind the optimum mutation given the expected reduction in nucleotide diversity (B value) in a locus.\n\nReturns\n\nadap.thetaF::Float64: changes adap.thetaF value.\n\n\n\n\n\n","category":"function"},{"location":"reference/#Analytical.setPpos!","page":"Reference","title":"Analytical.setPpos!","text":"setPpos!(param)\n\nFind the probabilty of positive selected alleles given the model. It solves a equation system taking into account fixations probabilities of weakly and strong beneficial alleles.\n\nReturns\n\nTuple{Float64,Float64}: weakly and strong beneficial alleles probabilites.\n\n\n\n\n\n","category":"function"},{"location":"reference/#Analytical.binomOp!","page":"Reference","title":"Analytical.binomOp!","text":"binomOp(param)\n\nBinomial convolution to sample the allele frequencies probabilites depeding on background selection values, and sample size.\n\nArguments\n\nparam::parameters\nconvolutedSamples::binomialDict\n\nReturns\n\nArray{Float64,2}: convoluted SFS given for each B value defined in the model. Results saved at param.bn.\n\n\n\n\n\n","category":"function"},{"location":"reference/#Analytical.phiReduction","page":"Reference","title":"Analytical.phiReduction","text":"phiReduction(param,gamma,ppos)\n\nReduction in fixation probabilty due to background selection and linkage. The formulas used have been subjected to several theoretical works (Charlesworth B., 1994, Hudson et al., 1995, Nordborg et al. 1995, Barton NH., 1995).\n\nThe fixation probabilty of selected alleles are reduce by a factor phi:\n\nphi(ts) = e^frac-2mut(1+fracrLt+frac2st)\n\nMultiplying across all deleterious linkes sites, we find:\n\nPhi = prod_1^L = phi(ts) = e^frac-2tmu(psi1fracr+2s+Lr - psi1fracr(L+1)+2s+tr)r^2\n\nphi(ts) = e^frac-2tmu(psi1fracr+2s+Lr - psi1fracr(L+1)+2s+tr)r^2\n\nArguments\n\ngamma::Int64: selection coefficient.\n\nReturns\n\nFloat64: expected rate of positive fixations under background selection.\n\n\n\n\n\n","category":"function"},{"location":"reference/#Analytical.analyticalAlpha","page":"Reference","title":"Analytical.analyticalAlpha","text":"analyticalAlpha(param, convolutedSamples)\n\nAnalytical α(x) estimation. Solve α(x) generally. We used the expected rates of divergence and polymorphism to approach the asympotic value accouting for background selection, weakly and strong positive selection. α(x) can be estimated taking into account the role of positive selected alleles or not. In this way we explore the role of linkage to deleterious alleles in the coding region.\n\nmathbbEalpha_x =  1 - left(fracmathbbED_smathbbED_NfracmathbbEP_NmathbbEP_Sright)\n\nArguments\n\nparam::parameters\nconvolutedSamples::binomialDict\n\nReturns\n\nArray{Float64,1} α(x).\n\n\n\n\n\n","category":"function"},{"location":"reference/#Analytical-estimation-1","page":"Reference","title":"Analytical estimation","text":"","category":"section"},{"location":"reference/#Fixations-1","page":"Reference","title":"Fixations","text":"","category":"section"},{"location":"reference/#","page":"Reference","title":"Reference","text":"Analytical.fixNeut\nAnalytical.fixNegB\nAnalytical.pFix\nAnalytical.fixPosSim","category":"page"},{"location":"reference/#Analytical.fixNeut","page":"Reference","title":"Analytical.fixNeut","text":"fixNeut()\n\nExpected neutral fixations rate reduce by B value.\n\nmathbbED_s = (1 - p_- - p_+) B frac12N\n\nReturns\n\nFloat64: expected rate of neutral fixations.\n\n\n\n\n\n","category":"function"},{"location":"reference/#Analytical.fixNegB","page":"Reference","title":"Analytical.fixNegB","text":"fixNegB(ppos)\n\nExpected fixation rate from negative DFE.\n\nmathbbED_n- =  p_-left(2^-alphabeta^alphaleft(-zetaalphafrac2+beta2 + zetaalpha12(2-frac1N+beta)right)right)\n\nArguments\n\nppos::Float64: positive selected alleles probabilty.\n\nReturns\n\nFloat64: expected rate of fixations from negative DFE.\n\n\n\n\n\n","category":"function"},{"location":"reference/#Analytical.pFix","page":"Reference","title":"Analytical.pFix","text":"pFix()\n\nExpected positive fixation rate.\n\nmathbbED_n+ =  p_+ cdot B cdot (1 - e^(-2s))\n\nArguments\n\nppos::Float64: positive selected alleles probabilty.\n\nReturns\n\nFloat64: expected rate of positive fixation.\n\n\n\n\n\n","category":"function"},{"location":"reference/#Analytical.fixPosSim","page":"Reference","title":"Analytical.fixPosSim","text":"fixPosSim(gamma,ppos)\n\nExpected positive fixations rate reduced due to the impact of background selection and linkage. The probabilty of fixation of positively selected alleles is reduced by a factor Φ across all deleterious linked sites Analytical.phiReduction.\n\nmathbbED_n+ =  Phi cdot mathbbED_n+\n\nArguments\n\nppos::Float64: positive selected alleles probabilty.\n\nReturns\n\nFloat64: expected rate of positive fixations under background selection\n\n\n\n\n\n","category":"function"},{"location":"reference/#Polymorphism-1","page":"Reference","title":"Polymorphism","text":"","category":"section"},{"location":"reference/#","page":"Reference","title":"Reference","text":"Analytical.DiscSFSNeutDown\nAnalytical.DiscSFSSelPosDown\nAnalytical.DiscSFSSelNegDown\nAnalytical.cumulativeSfs","category":"page"},{"location":"reference/#Analytical.DiscSFSNeutDown","page":"Reference","title":"Analytical.DiscSFSNeutDown","text":"DiscSFSNeutDown()\n\nExpected rate of neutral allele frequency reduce by backgrou\tnd selection. The spectrum depends on the number of individual []\n\nmathbbEPs_(x) = sumx^*=xx^*=1f_B(x)\n\nReturn:\n\nArray{Float64}: expected rate of neutral alleles frequencies.\n\n\n\n\n\n","category":"function"},{"location":"reference/#Analytical.DiscSFSSelPosDown","page":"Reference","title":"Analytical.DiscSFSSelPosDown","text":"DiscSFSSelPosDown(gammaValue,ppos)\n\nExpected rate of positive selected allele frequency reduce by background selection. The spectrum depends on the number of individuals.\n\nArguments\n\ngammaValue::Int64: selection strength.\nppos::Float64: positive selected alleles probabilty.\n\nReturn:\n\nArray{Float64}: expected positive selected alleles frequencies.\n\n\n\n\n\n","category":"function"},{"location":"reference/#Analytical.DiscSFSSelNegDown","page":"Reference","title":"Analytical.DiscSFSSelNegDown","text":"DiscSFSSelNegDown(param,ppos)\n\nExpected rate of positive selected allele frequency reduce by background selection. Spectrum drawn on a gamma DFE. It depends on the number of individuals.\n\nArguments\n\nppos::Float64: positive selected alleles probabilty.\n\nReturn:\n\nArray{Float64}: expected negative selected alleles frequencies.\n\n\n\n\n\n","category":"function"},{"location":"reference/#Analytical.cumulativeSfs","page":"Reference","title":"Analytical.cumulativeSfs","text":"cumulativeSfs(sfsTemp)\n\nChanging SFS considering all values above a frequency x. The original asymptotic-MK approach takes Pn(x) and Ps(x) as the number of polymorphic sites at frequency x rather than above x, but this approach scales poorly as sample size increases. We define the polymorphic spectrum as stated above since these quantities trivially have the same asymptote but are less affected by changing sample size.\n\n\n\n\n\n","category":"function"},{"location":"reference/#Summary-statistics-1","page":"Reference","title":"Summary statistics","text":"","category":"section"},{"location":"reference/#","page":"Reference","title":"Reference","text":"Analytical.poissonFixation\nAnalytical.poissonPolymorphism\nAnalytical.sampledAlpha\nAnalytical.iterRates\nAnalytical.gettingRates\nAnalytical.summaryStatsFromRates","category":"page"},{"location":"reference/#Analytical.poissonFixation","page":"Reference","title":"Analytical.poissonFixation","text":"poissonFixation(observedValues,λds, λdn)\n\nDivergence sampling from Poisson distribution. The expected neutral and selected fixations are subset through their relative expected rates (fixNeut, fixNegB, fixPosSim). Empirical values are used are used to simulate the locus L along a branch of time T from which the expected Ds and Dn raw count estimated given the mutation rate (mu). Random number generation is used to subset samples arbitrarily given the success rate lambda in the distribution.\n\nmathbbED_N = X in Poissonleft(lambda = D times leftfracmathbbED_+ + mathbbED_-mathbbED_+ + mathbbED_- + mathbbED_0rightright)\n\nmathbbED_S = X in Poissonleft(lambda = D times leftfracmathbbED_0mathbbED_+ + mathbbED_- + mathbbED_0rightright)\n\nArguments\n\nobservedValues::Array: Array containing the total observed divergence.\nλds::Float64: expected neutral fixations rate.\nλdn::Float64: expected selected fixations rate.\n\nReturns\n\nArray{Int64,1} containing the expected count of neutral and selected fixations.\n\n\n\n\n\n","category":"function"},{"location":"reference/#Analytical.poissonPolymorphism","page":"Reference","title":"Analytical.poissonPolymorphism","text":"poissonPolymorphism(observedValues,λps,λpn)\n\nPolymorphism sampling from Poisson distributions. The total expected neutral and selected polimorphism are subset through the relative expected rates at the frequency spectrum (fixNeut, DiscSFSNeutDown,). Empirical sfs are used to simulate the locus L along a branch of time T from which the expected Ps and Pn raw count are estimated given the mutation rate (mu). Random number generation is used to subset samples arbitrarily from the whole sfs given each frequency success rate lambda in the distribution.\n\nThe success rate managing the Poisson distribution by the observed count each frequency.  We considered both sampling variance and process variance is affecting the number of variable alleles we sample from SFS. This variance arises from the random mutation-fixation process along the branch. To incorporate this variance we do one sample per frequency-bin and use the total sampled variation and the SFS for the summary statistics.\n\nmathbbEP_N = sum_x=0^x=1 X in Poissonleft(lambda = SFS_(x) times leftfracmathbbEP_+(x) + mathbbEP_-(x)mathbbEP_+(x) + mathbbEP_-(x) + mathbbEP_0(x)rightright)\n\nmathbbEP_S = sum_x=0^x=1 X in Poissonleft(lambda = SFS_(x) times leftfracmathbbEP_0(x)mathbbEP_+(x) + mathbbEP_-(x) + mathbbEP_0(x)rightright)\n\nArguments\n\nobservedValues::Array{Int64,1}: Array containing the total observed divergence.\nλps::Array{Float64,1}: expected neutral site frequency spectrum rate.\nλpn::Array{Float64,1}: expected selected site frequency spectrum rate.\n\nReturns\n\nArray{Int64,2} containing the expected total count of neutral and selected polymorphism.\n\n\n\n\n\n","category":"function"},{"location":"reference/#Analytical.sampledAlpha","page":"Reference","title":"Analytical.sampledAlpha","text":"sampledAlpha(observedValues,λds, λdn)\n\nOuput the expected values from the Poisson sampling process. Please check poissonFixation and poissonPolymorphism to understand the samplingn process. α(x) is estimated through the expected values of Dn, Ds, Pn and Ps.\n\nArguments\n\nparam::parameters: Array containing the total observed divergence.\nd::Array: observed divergence.\nafs::Array: observed polymorphism.\nλdiv::Array{Float64,2}: expected fixations rate.\nλdiv::Array{Float64,2}: expected site frequency spectrum rates.\n\nReturns\n\nαS,expDn,expDs,expPn,expPs,ssAlpha\n\nArray{Int64,2} containing α(x) values.\nArray{Int64,1} expected non-synonymous divergence.\nArray{Int64,1} expected synonymous divergence.\nArray{Int64,1} expected non-synonymous polymorphism.\nArray{Int64,1} expected synonymous polymorphism.\nArray{Int64,1} expected synonymous polymorphism.\nArray{Int64,1} expected synonymous polymorphism.\nArray{Int64,2} containing α(x) binned values.\n\n\n\n\n\n","category":"function"},{"location":"reference/#Analytical.iterRates","page":"Reference","title":"Analytical.iterRates","text":"iterRates(param::parameters,afac::Float64,bfac::Float64,alTot::Float64,alLow::Float64,divergence::Array,sfs::Array)\n\nEstimating rates given a model for all B range.\n\nArguments\n\nparam::parameters\nconvolutedSamples::binomialDict\nalTot::Float64\nalLow::Float64\ngH::Int64\ngL::Int64\ngamNeg::Int64\nafac::Float64\nρ::Float64\nθ::Float64\n\nOutput\n\nArray{Float64,2}\n\n\n\n\n\n","category":"function"},{"location":"reference/#Analytical.gettingRates","page":"Reference","title":"Analytical.gettingRates","text":"gettingRates(gammaL,gammaH,pposL,pposH,observedData,nopos)\n\nEstimating analytical rates of fixation and polymorphism to approach α value accouting for background selection, weakly and strong positive selection. Output values will be used to sample from a Poisson distribution the total counts of polymorphism and divergence using observed data. \n\nArguments\n\nparam::parameters\ncnvBinom::SparseMatrixCSC{Float64,Int64}\n\nReturns\n\nArray{Float64,2} containing solved model, fixation and polymorphic rates\n\n\n\n\n\n","category":"function"},{"location":"reference/#Analytical.summaryStatsFromRates","page":"Reference","title":"Analytical.summaryStatsFromRates","text":"param::parameters,rates::JLD2.JLDFile,analysisFolder::String,summstatSize::Int64,replicas::Int64,bootstrap::Bool)\n\nEstimate summary statistics using observed data and analytical rates. analysisFolder will check for the SFS and divergence file and will be used to output summary statistics.\n\nArguments\n\nparam::parameters\nrates::JLD2.JLDFile\nanalysisFolder::String\nsummstatSize::Int64\nreplicas::Int64\nbootstrap::Bool\n\nOutput\n\nObserded data and summary statistics to ABC inference\n\n\n\n\n\n","category":"function"},{"location":"reference/#Inference-tools-1","page":"Reference","title":"Inference tools","text":"","category":"section"},{"location":"reference/#","page":"Reference","title":"Reference","text":"Analytical.parseSfs\nAnalytical.ABCreg","category":"page"},{"location":"reference/#Analytical.parseSfs","page":"Reference","title":"Analytical.parseSfs","text":"parseSfs(;data,output,sfsColumns,divColumns)\n\nFunction to parse polymorphism and divergence by subset of genes. The input data is based on supplementary material described at Uricchio et al. 2019. Please be sure the file is tabulated.\n\nGeneId Pn DAF seppareted by commas Ps DAF separated by commas Dn Ds\nXXXX 0 ,0,0,0,0,0,0,0,0 0 ,0,0,0,0,0,0,0,0 0 0\nXXXX 0 ,0,0,0,0,0,0,0,0 0 ,0,0,0,0,0,0,0,0 0 0\nXXXX 0 ,0,0,0,0,0,0,0,0 0 ,0,0,0,0,0,0,0,0 0 0\n\nArguments\n\ndata: String or Array of strings containing files names with full path.\noutput::String: path to save file. Containing one file per input file.\nsfsColumns::Array{Int64,1}: non-synonymous and synonymous daf columns. Please introduce first the non-synonymous number.\ndivColumns::Array{Int64,1}: non-synonymous and synonymous divergence columns. Please introduce first the non-synonymous number.\n\nReturns\n\nArray{Float64,1}: α values\nArray{Float64,2}: Site Frequency Spectrum\nArray{Float64,1}: Synonymous and non-synonymous divergence counts\n\n\n\n\n\n\n","category":"function"},{"location":"reference/#Analytical.ABCreg","page":"Reference","title":"Analytical.ABCreg","text":"ABCreg(analysis, replicas, P, S, tol, workers, abcreg, parallel)\n\nCould be parallelize if GNU parallel is available in your system\n\n\n\n\n\n","category":"function"},{"location":"summstat/#Summary-statistics-1","page":"Summary statistics","title":"Summary statistics","text":"","category":"section"},{"location":"summstat/#","page":"Summary statistics","title":"Summary statistics","text":"To estimate summary statistics, we used the estimated analytical rates and empirical data following the description at section Empirical estimation","category":"page"},{"location":"summstat/#","page":"Summary statistics","title":"Summary statistics","text":"Before starting the summary statistics, consider parallelizing the process using Julia Distributed computing. If you are following the tutorial step by step, do not input the following commands.","category":"page"},{"location":"summstat/#","page":"Summary statistics","title":"Summary statistics","text":"using Distributed\naddprocs(7)\n\n@everywhere using Analytical, CSV, DataFrames, JLD2, ProgressMeter","category":"page"},{"location":"summstat/#","page":"Summary statistics","title":"Summary statistics","text":"Load your analytical rates and declare a model specifying a DAC. The selected DAC will be used to subset summary statistics. You only can input DAC values already estimated. To check the selected DAC at rates estimations, you can access the HDF5 file","category":"page"},{"location":"summstat/#","page":"Summary statistics","title":"Summary statistics","text":"# Opening rates\nh5file   = jldopen(\"/home/jmurga/rates.jld2\")\n# Checking estimated dac\nadap = Analytical.parameters(n=661)\nh5file[\"1000/\" * string(adap.n) * \"/dac\"]\n# Selecting dac to perform summary statistics\nadap.dac = [2,4,5,10,20,50,200,661,925]","category":"page"},{"location":"summstat/#","page":"Summary statistics","title":"Summary statistics","text":"To standardize the summary statistic estimation, the function Analytical.summaryStatsFromRates will search and read the SFS and divergence files into an analysis folder. Please be sure that you write the SFS and divergence files using the prefix sfs and div to read the files correctly. Otherwise, the function will not read the files correctly.","category":"page"},{"location":"summstat/#","page":"Summary statistics","title":"Summary statistics","text":"We include the argument bootstrap to perform bootstrap analysis following polyDFE","category":"page"},{"location":"summstat/#","page":"Summary statistics","title":"Summary statistics","text":"@time summstat = Analytical.summaryStatsFromRates(param=adap,rates=h5file,analysisFolder=\"/home/jmurga/tgpData/\",summstatSize=10^5,replicas=100,bootstrap=true);","category":"page"},{"location":"summstat/#","page":"Summary statistics","title":"Summary statistics","text":"The function will create summary statistics files and empirical data input at ABC inference","category":"page"},{"location":"#ABC-MK-1","page":"Home","title":"ABC-MK","text":"","category":"section"},{"location":"#","page":"Home","title":"Home","text":"ABC-MK is an analytical approximation to alpha_(x). We have explored the impact of linkage and background selection at positive selected alleles sites. The package solves analytical approximations for different genetic scenarios to estimate the strength and rate of adaptation.","category":"page"},{"location":"#","page":"Home","title":"Home","text":"Our approach directly estimates alpha_(x) and several statistics (B, alpha_W, alpha_S) associated with random DFE. In conjunction, the associated values to these DFE can be used as summary statistics at ABC methods. Therefore, our method can estimate the rate and strength of adaption in models and non-models organisms.","category":"page"},{"location":"#Docker-installation-1","page":"Home","title":"Docker installation","text":"","category":"section"},{"location":"#","page":"Home","title":"Home","text":"We highly recommend using the Docker image to execute the software. The Docker image is based on Debian and includes all the software needed to run the pipeline. You can access to Debian system or Jupyter pulling the image from Docker Hub. Remember to link the folder /analysis with any folder at your ${HOME} directory to save the results:","category":"page"},{"location":"#","page":"Home","title":"Home","text":"# Pull the image\ndocker pull jmurga/abcmk\n# Run docker linking some local volume to export data\ndocker run -i -t -v ${HOME}/<folderPath>:/analysis/folder jmurga/abcmk\n# Run jupyter notebook from docker image. Change the port if 8888 is already used\ndocker run -i -t -v ${HOME}/<folderPath>:/analysis/folder -p 8888:8888 jmurga/abcmk /bin/bash -c \"jupyter-lab --ip='*' --port=8888 --no-browser --allow-root\"","category":"page"},{"location":"#","page":"Home","title":"Home","text":"To use our command-line interface, just run","category":"page"},{"location":"#","page":"Home","title":"Home","text":"docker run -i -t -v ${HOME}/test/:/analysis/test/ jmurga/abcmk /analysis/abcmk_cli.jl","category":"page"},{"location":"#Singularity-installation-1","page":"Home","title":"Singularity installation","text":"","category":"section"},{"location":"#","page":"Home","title":"Home","text":"We have created a Singularity container to use the software in HPC systems. We have tested the software at HPC working with SLURM and HTCondor scheduler","category":"page"},{"location":"#","page":"Home","title":"Home","text":"singularity pull --arch amd64 library://jmurga/default/abcmk:latest","category":"page"},{"location":"#","page":"Home","title":"Home","text":"We found a bug regarding Singularity, ClusterManagers.jl and SLURM in our HPC tests. Please, consider to install the packages manually if your HPC works with SLURM. We provided a Julia script to easily install all the required packages. Just run it before to execute our Command-Line Interface. Here is an example showing the rates estimation in SLURM:","category":"page"},{"location":"#","page":"Home","title":"Home","text":"#!/bin/bash\n\n#SBATCH --partition=XXXX\n#SBATCH --qos=XXXX\n#SBATCH --nodes=4\n#SBATCH --ntasks=40\n#SBATCH --ntasks-per-node=10\n#SBATCH --mem=40GB\n#SBATCH --job-name=pjulia\n#SBATCH --time=01:00:00\n#SBATCH --mail-type=ALL\n#SBATCH --account=XXXX\n#SBATCH --mail-user=XXXX\n\nml julia\n\n# Delete this line if you have already installed the packages\njulia jl_dependencies.jl\n\njulia abcmk_cli.jl rates --samples 661 --gamNeg -2000,-200 --gL 1,10 --gH 200,2000 --rho 0.001 --theta 0.001 --solutions 100000 --output rates.jld2 --dac 1,2,4,5,10,20,50,100,200,400,500,661,925,1000 --scheduler slurm --nthreads 40","category":"page"},{"location":"#","page":"Home","title":"Home","text":"Here is the same example showing an execution in HTCondor with Singularity:","category":"page"},{"location":"#","page":"Home","title":"Home","text":"executable=/bin/singularity\narguments=\"exec abcmk_latest.sif julia abcmk_cli.jl rates --samples 661 --gamNeg -2000,-200 --gL 1,10 --gH 200,2000 --rho 0.001 --theta 0.001 --solutions 100000 --output rates.jld2 --dac 1,2,4,5,10,20,50,100,200,400,500,661,925,1000 --nthreads 24 --scheduler htcondor\"\n\nrequest_cpus=24\nrequest_memory=24G\n\nerror = err1.out\nlog = log1.out\n\n+flavour=\"short\"\n\nqueue 1 ","category":"page"},{"location":"#Scratch-installation-1","page":"Home","title":"Scratch installation","text":"","category":"section"},{"location":"#","page":"Home","title":"Home","text":"To install our module from scratch, we highly recommend using LTS official Julia binaries","category":"page"},{"location":"#","page":"Home","title":"Home","text":"JULIA_VERSION=1.6.1\ncurl -o ${HOME}/julia-${JULIA_VERSION}-linux-x86_64.tar.gz https://julialang-s3.julialang.org/bin/linux/x64/1.6/julia-${JULIA_VERSION}-linux-x86_64.tar.gz\ntar -zxf ${HOME}/julia-${JULIA_VERSION}-linux-x86_64.tar.gz -C ${HOME}","category":"page"},{"location":"#","page":"Home","title":"Home","text":"If this is your first time using Julia, please remember to export Julia binaries to your path. In this way, you will execute Julia using the command julia","category":"page"},{"location":"#","page":"Home","title":"Home","text":"echo 'export PATH=\"${HOME}/julia-${JULIA_VERSION}/bin:$PATH\"' >> ${HOME}/.bashrc\nsource ${HOME}/.bashrc","category":"page"},{"location":"#","page":"Home","title":"Home","text":"Consider to install some important dependencies to automatize your ABC-MK pipelines. We have prepared a file to install them. Please download this file and execute the following command","category":"page"},{"location":"#","page":"Home","title":"Home","text":"wget https://raw.githubusercontent.com/jmurga/Analytical.jl/master/scripts/julia_dependencies.jl\njulia julia_dependencies.jl","category":"page"},{"location":"#","page":"Home","title":"Home","text":"You can easly install our Julia package executing","category":"page"},{"location":"#","page":"Home","title":"Home","text":"julia -e 'using Pkg;Pkg.add(PackageSpec(path=\"https://github.com/jmurga/Analytical.jl\"))'","category":"page"},{"location":"#","page":"Home","title":"Home","text":"Or from Pkg REPL (by pressing ] at Julia interpreter):","category":"page"},{"location":"#","page":"Home","title":"Home","text":"add https://github.com/jmurga/Analytical.jl","category":"page"},{"location":"#ABCreg-1","page":"Home","title":"ABCreg","text":"","category":"section"},{"location":"#","page":"Home","title":"Home","text":"We have linked ABCreg with Julia to perform ABC inference. Nonetheless others ABC softwares could be used (abc (R package), ABCToolBox, etc). If you are going to use ABCreg to directly make inference from our software please cite the publication and compile it in your system. Anyway, once you get the summary statistic files you can use any other ABC software.","category":"page"},{"location":"#","page":"Home","title":"Home","text":"ABCreg needs GSL and libz to work. Please install both libraries before compile the software:","category":"page"},{"location":"#","page":"Home","title":"Home","text":"sudo apt install libgsl-dev libz-dev build-essential git","category":"page"},{"location":"#","page":"Home","title":"Home","text":"git clone https://github.com/molpopgen/ABCreg.git ${HOME}/ABCreg\ncd ${HOME}/ABCreg/src && make","category":"page"},{"location":"#","page":"Home","title":"Home","text":"Once ABCreg is installed you can add the binary to your PATH:","category":"page"},{"location":"#","page":"Home","title":"Home","text":"echo 'export PATH=\"${HOME}/ABCreg/src/:$PATH\"' >> ${HOME}/.bashrc\nsource ${HOME}/.bashrc","category":"page"},{"location":"#R-1","page":"Home","title":"R","text":"","category":"section"},{"location":"#","page":"Home","title":"Home","text":"We have used R to estimate the Maximum-A-Posteriori (MAP) from posterior distributions following ABCreg examples. We linked Julia and R internally. The module contains functions to perform the estimations without quit the Julia session.","category":"page"},{"location":"#","page":"Home","title":"Home","text":"If you are going to perform MAP estimates and plot using our module, be sure you have installed R and the following packages: ggplot2 and data.table, locfit. ","category":"page"},{"location":"#","page":"Home","title":"Home","text":"R -e \"install.packages(c('ggplot2','data.table','locfit'))\"","category":"page"},{"location":"#Dependencies-1","page":"Home","title":"Dependencies","text":"","category":"section"},{"location":"#","page":"Home","title":"Home","text":"All Julia dependencies are installed within the package. You don't need to install them manually.","category":"page"},{"location":"#Mandatory-dependencies-to-solve-the-analytical-equations-1","page":"Home","title":"Mandatory dependencies to solve the analytical equations","text":"","category":"section"},{"location":"#","page":"Home","title":"Home","text":"Roots - root finding.\nNLsolve - non-linear systems of equations solver.\nDistributions - probability distributions.\nSpecialFunctions - special mathematical functions in Julia.\nQuadmath - multiprecision numerical computing.\nPoissonRandom - Poisson random number generator.\nParameters - custom keyword constructor.","category":"page"},{"location":"#The-following-dependencies-are-required-to-use-all-the-funcionalities-(parse-SFS,-plots,-parse-multi-Fasta,-etc.)-1","page":"Home","title":"The following dependencies are required to use all the funcionalities (parse SFS, plots, parse multi-Fasta, etc.)","text":"","category":"section"},{"location":"#","page":"Home","title":"Home","text":"CSV\nParsers\nStatsBase\nDataFrames\nGZip\nOrderedCollections\nPlots\nFastaIO","category":"page"},{"location":"#References-1","page":"Home","title":"References","text":"","category":"section"},{"location":"#","page":"Home","title":"Home","text":"Uricchio, L.H., Petrov, D.A. & Enard, D. Exploiting selection at linked sites to infer the rate and strength of adaptation. Nat Ecol Evol 3, 977–984 (2019). https://doi.org/10.1038/s41559-019-0890-6\nPhilipp W. Messer, Dmitri A. Petrov. Frequent adaptation and the McDonald–Kreitman test. Proceedings of the National Academy of Sciences May 2013, 110 (21) 8615-8620. https://doi.org/10.1073/pnas.1220835110\nNordborg, M., Charlesworth, B., & Charlesworth, D. (1996). The effect of recombination on background selection. Genetical Research, 67(2), 159-174. https://doi.org/10.1017/S0016672300033619\nR R Hudson and N L Kaplan. Deleterious background selection with recombination. Genetics December 1, 1995 vol. 141 no. 4 1605-1617.\nLinkage and the limits to natural selection. N H Barton. Genetics June 1, 1995 vol. 140 no. 2 821-841\nThornton, K.R. Automating approximate Bayesian computation by local linear regression. BMC Genet 10, 35 (2009). https://doi.org/10.1186/1471-2156-10-35","category":"page"}]
}
